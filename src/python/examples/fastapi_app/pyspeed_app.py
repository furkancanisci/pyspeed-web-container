"""
PySpeed Accelerated FastAPI Application

This demonstrates how to run the FastAPI test application with PySpeed acceleration
for massive async performance improvements.
"""

import sys
import os
import asyncio

# Add the pyspeed module to the path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

try:
    from pyspeed import PySpeedContainer
    from app import app
    print("âœ… PySpeed module loaded successfully")
    print("âœ… FastAPI app imported successfully")
except ImportError as e:
    print(f"âŒ Failed to import dependencies: {e}")
    print("ðŸ’¡ Make sure to install requirements and build C++ extensions:")
    print("   pip install fastapi uvicorn pydantic")
    print("   cd /path/to/pyspeed-web-container")
    print("   make build")
    sys.exit(1)

def main():
    """Run FastAPI app with PySpeed acceleration"""
    
    print("ðŸš€ Starting PySpeed Accelerated FastAPI Application")
    print("=" * 65)
    
    # Optimized configuration for async workloads
    config = {
        'threads': 12,  # More threads for async workloads
        'enable_compression': True,  # Enable gzip compression
        'enable_static_cache': True,  # Cache static files
        'static_cache_size': 512,  # 512MB cache for static files
        'max_request_size': 20 * 1024 * 1024,  # 20MB max request size
        'keep_alive_timeout': 60,  # 60 second keep-alive for persistent connections
        'use_memory_pool': True,  # Use memory pool for better performance
        'enable_zero_copy': True,  # Enable zero-copy optimizations
        'io_buffer_size': 128 * 1024,  # 128KB I/O buffer for better async performance
    }
    
    # Create PySpeed container with FastAPI app
    container = PySpeedContainer(app, config=config, framework='fastapi')
    
    # Add static file route for better performance
    static_dir = os.path.join(os.path.dirname(__file__), 'static')
    if os.path.exists(static_dir):
        container.add_static_route('/static', static_dir)
        print(f"ðŸ“ Added static file route: /static -> {static_dir}")
    
    print("\nðŸ“Š Performance Configuration (Async Optimized):")
    print(f"   - Worker threads: {config['threads']} (optimized for async)")
    print(f"   - I/O buffer size: {config['io_buffer_size'] // 1024}KB")
    print(f"   - Keep-alive timeout: {config['keep_alive_timeout']}s")
    print(f"   - Compression: {'Enabled' if config['enable_compression'] else 'Disabled'}")
    print(f"   - Static cache: {config['static_cache_size']}MB")
    print(f"   - Memory pool: {'Enabled' if config['use_memory_pool'] else 'Disabled'}")
    print(f"   - Zero-copy: {'Enabled' if config['enable_zero_copy'] else 'Disabled'}")
    
    print("\nðŸ”— Available Endpoints:")
    print("   - http://localhost:8080/                    - API info")
    print("   - http://localhost:8080/health              - Health check")
    print("   - http://localhost:8080/api/users           - Async user list")
    print("   - http://localhost:8080/api/async-test      - Concurrent operations test")
    print("   - http://localhost:8080/api/large-json      - Large async JSON test")
    print("   - http://localhost:8080/api/stream          - Streaming response test")
    print("   - http://localhost:8080/static-test         - Static file test")
    print("   - http://localhost:8080/docs                - Interactive API docs")
    print("   - http://localhost:8080/benchmark           - Performance info")
    
    print("\nðŸ’¡ Async Performance Testing Commands:")
    print("   # Test concurrent async operations")
    print("   curl -s 'http://localhost:8080/api/async-test?operations=100&delay=2.0' | jq .")
    print()
    print("   # Test large async JSON generation")
    print("   time curl -s 'http://localhost:8080/api/large-json?size=5000&complexity=complex' > /dev/null")
    print()
    print("   # Test async POST processing")
    print("   curl -X POST 'http://localhost:8080/api/json-processing' \\")
    print("        -H 'Content-Type: application/json' \\")
    print("        -d '{\"data\": {\"test\": \"async_value\"}, \"options\": {\"process_strings\": true}}'")
    print()
    print("   # Load test async endpoints (requires wrk)")
    print("   wrk -t12 -c200 -d30s --latency http://localhost:8080/api/users")
    print("   wrk -t12 -c200 -d30s --latency 'http://localhost:8080/api/async-test?operations=10'")
    print()
    print("   # Compare with standard FastAPI (different port)")
    print("   # Standard: uvicorn app:app --host 0.0.0.0 --port 8000")
    print("   # PySpeed:  python pyspeed_app.py")
    
    print("\nðŸ”¬ Expected Async Performance Improvements:")
    print("   - 10-100x higher concurrent request handling")
    print("   - 50-90% lower response latency")
    print("   - 30-70% lower memory usage per connection")
    print("   - Better CPU utilization for I/O-bound operations")
    print("   - Reduced async/await overhead")
    
    print("\nðŸš€ Starting server on http://0.0.0.0:8080")
    print("   Framework: FastAPI (async)")
    print("   Container: PySpeed C++ Acceleration")
    print("   Press Ctrl+C to stop")
    print("=" * 65)
    
    try:
        # Run the accelerated server
        container.run(host='0.0.0.0', port=8080)
        
    except KeyboardInterrupt:
        print("\n\nðŸ›‘ Shutting down PySpeed FastAPI server...")
        
        # Print final statistics
        stats = container.get_stats()
        if stats:
            print("\nðŸ“Š Final Async Performance Statistics:")
            print(f"   - Requests processed: {stats.get('requests_processed', 0):,}")
            print(f"   - Bytes sent: {stats.get('bytes_sent', 0):,}")
            print(f"   - Bytes received: {stats.get('bytes_received', 0):,}")
            print(f"   - Average RPS: {stats.get('requests_per_second', 0):.1f}")
            print(f"   - Cache hit ratio: {stats.get('cache_hit_ratio', 0)*100:.1f}%")
            print(f"   - JSON requests: {stats.get('json_requests', 0):,}")
            print(f"   - Average parse time: {stats.get('average_parse_time_us', 0):.2f}Î¼s")
            print(f"   - Average response build time: {stats.get('average_build_time_us', 0):.2f}Î¼s")
            
            # Calculate efficiency metrics
            total_requests = stats.get('requests_processed', 1)
            total_errors = stats.get('errors', 0)
            success_rate = ((total_requests - total_errors) / total_requests) * 100
            print(f"   - Success rate: {success_rate:.2f}%")
        
        print("âœ… FastAPI server stopped cleanly")

def compare_async_performance():
    """
    Utility function to compare PySpeed vs standard FastAPI async performance
    """
    print("ðŸ”¬ Async Performance Comparison Utility")
    print("=" * 55)
    print()
    print("To compare async performance between standard FastAPI and PySpeed:")
    print()
    print("1ï¸âƒ£  Run standard FastAPI app:")
    print("   uvicorn app:app --host 0.0.0.0 --port 8000 --workers 1")
    print("   # Server runs on http://localhost:8000")
    print()
    print("2ï¸âƒ£  In another terminal, run PySpeed version:")
    print("   python pyspeed_app.py")
    print("   # Server runs on http://localhost:8080")
    print()
    print("3ï¸âƒ£  Compare async operation performance:")
    print("   # Standard FastAPI")
    print("   time curl -s 'http://localhost:8000/api/async-test?operations=100&delay=2.0' > /dev/null")
    print()
    print("   # PySpeed accelerated")
    print("   time curl -s 'http://localhost:8080/api/async-test?operations=100&delay=2.0' > /dev/null")
    print()
    print("4ï¸âƒ£  Load test concurrent connections:")
    print("   # Standard FastAPI")
    print("   wrk -t8 -c200 -d30s --latency http://localhost:8000/api/users")
    print()
    print("   # PySpeed accelerated")
    print("   wrk -t8 -c200 -d30s --latency http://localhost:8080/api/users")
    print()
    print("5ï¸âƒ£  Test large async JSON generation:")
    print("   # Standard FastAPI")
    print("   time curl -s 'http://localhost:8000/api/large-json?size=5000&complexity=complex' > /dev/null")
    print()
    print("   # PySpeed accelerated")
    print("   time curl -s 'http://localhost:8080/api/large-json?size=5000&complexity=complex' > /dev/null")
    print()
    print("ðŸ“ˆ Expected improvements with PySpeed for async workloads:")
    print("   - 10-100x higher concurrent request capacity")
    print("   - 50-90% lower latency for async operations")
    print("   - 30-70% lower memory usage per connection")
    print("   - Better scaling for I/O-bound async tasks")
    print("   - Reduced Python async/await overhead")
    print("   - More efficient event loop integration")

def benchmark_async_specific():
    """
    Run specific async benchmarks
    """
    print("ðŸƒâ€â™‚ï¸ Running Async-Specific Benchmarks...")
    
    import requests
    import time
    import json
    
    base_url = "http://localhost:8080"
    
    # Test if server is running
    try:
        response = requests.get(f"{base_url}/health", timeout=5)
        if response.status_code != 200:
            print("âŒ PySpeed server not responding. Start it first with: python pyspeed_app.py")
            return
    except requests.exceptions.RequestException:
        print("âŒ PySpeed server not running. Start it first with: python pyspeed_app.py")
        return
    
    print("âœ… Server is running, starting benchmarks...")
    
    # Benchmark 1: Async operations
    print("\n1ï¸âƒ£  Testing concurrent async operations...")
    start_time = time.time()
    response = requests.get(f"{base_url}/api/async-test?operations=50&delay=1.0")
    end_time = time.time()
    
    if response.status_code == 200:
        data = response.json()
        print(f"   - Operations: {data['performance']['operations_count']}")
        print(f"   - Server processing time: {data['performance']['total_time']}s")
        print(f"   - Client total time: {end_time - start_time:.3f}s")
        print(f"   - Operations/sec: {data['performance']['operations_per_second']}")
    
    # Benchmark 2: Large JSON async generation
    print("\n2ï¸âƒ£  Testing large async JSON generation...")
    start_time = time.time()
    response = requests.get(f"{base_url}/api/large-json?size=3000&complexity=complex")
    end_time = time.time()
    
    if response.status_code == 200:
        data = response.json()
        print(f"   - Items generated: {data['metadata']['size_requested']}")
        print(f"   - Generation time: {data['metadata']['generation_time']}s")
        print(f"   - Total response time: {end_time - start_time:.3f}s")
        print(f"   - Estimated JSON size: {data['stats']['estimated_json_size_kb']:.1f} KB")
    
    # Benchmark 3: Async POST processing
    print("\n3ï¸âƒ£  Testing async JSON POST processing...")
    test_data = {
        "data": {f"key_{i}": f"value_{i}" for i in range(100)},
        "options": {"process_strings": True, "uppercase_keys": True}
    }
    
    start_time = time.time()
    response = requests.post(
        f"{base_url}/api/json-processing",
        json=test_data,
        headers={"Content-Type": "application/json"}
    )
    end_time = time.time()
    
    if response.status_code == 200:
        data = response.json()
        print(f"   - Items processed: {data['processing_info']['items_processed']}")
        print(f"   - Processing time: {data['processing_info']['processing_time']}s")
        print(f"   - Total time: {end_time - start_time:.3f}s")
    
    print("\nâœ… Async benchmarks completed!")

if __name__ == '__main__':
    if len(sys.argv) > 1:
        if sys.argv[1] == '--compare':
            compare_async_performance()
        elif sys.argv[1] == '--benchmark':
            benchmark_async_specific()
        else:
            print("Usage: python pyspeed_app.py [--compare|--benchmark]")
    else:
        main()